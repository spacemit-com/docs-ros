sidebar_position: 6

# 函数调用(Function Calling)

## 功能介绍

本章节介绍如何使用大语言模型（LLM）实现函数调用（Function Calling）。函数调用使得大模型不仅能够理解和生成自然语言，还能根据指令自动选择并调用本地或云端函数，实现从“能说”到“能做”的跃迁。

## 安装依赖

首先安装必要依赖，包括 Ollama 工具包和模型资源：

```bash
sudo apt update
sudo apt install spacemit-ollama-toolkit
```

## 模型制作

下载并创建所需的模型文件。

```bash
sudo apt install wget
wget https://modelscope.cn/models/second-state/Qwen2.5-0.5B-Instruct-GGUF/resolve/master/Qwen2.5-0.5B-Instruct-Q4_0.gguf -P ./
wget https://archive.spacemit.com/spacemit-ai/modelfile/qwen2.5:0.5b.modelfile -P ./

wget http://archive.spacemit.com/spacemit-ai/gguf/qwen2.5-0.5b-fc-q4_0.gguf -P ./
wget http://archive.spacemit.com/spacemit-ai/modelfile/qwen2.5-0.5b-fc.modelfile -P ./
```

使用 Ollama 创建本地模型：

```bash
ollama create qwen2.5:0.5b -f qwen2.5:0.5b.modelfile
ollama create qwen2.5-0.5b-fc -f qwen2.5-0.5b-fc.modelfile
```

## 克隆代码仓库

克隆项目代码仓库，并进入示例代码所在目录。

```bash
git clone https://gitee.com/bianbu/spacemit-demo.git
cd spacemit-demo/examples/NLP
```

## 运行示例代码

执行主程序脚本。程序启动后将等待用户输入。

```bash
python 05_llm_demo.py
```

运行后，大模型将根据用户输入的自然语言内容，解析意图并自动调用对应函数，返回结构化的响应或直接执行逻辑功能。
