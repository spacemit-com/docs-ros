---
sidebar_position: 1
slug: /05_AI_Feature_Experience/5.0_preliminary_knowledge
---

# 预备知识

在开始体验本章节中的示例与功能之前，建议先了解以下预备知识。
这些内容将帮助你快速上手，并理解我们的 **SpacemiT RISC-V AI 平台** 所支持的能力和生态。

## 快速开始示例

在 **[5.1 快速开始](5.1_quickly_start/index.md)** 章节中，我们提供了一系列 **典型 AI 功能演示**，包括：

- **语音相关**
  - 语音活动检测 (VAD)
  - 语音转文本 (ASR)
  - 文本转语音 (TTS)

- **大模型相关**
  - 大语言模型 (LLM)
  - 语音输入 → LLM 输出
  - 函数调用 (Function Call)
  - 视觉语言模型 (VLM)

这些示例覆盖了从语音到多模态的完整链路，帮助用户快速体验 **RISC-V 平台的端侧智能能力**。

由于示例中大量使用 Python 进行开发，请先阅读 [Python 开发指南](https://bianbu.spacemit.com/brdk/System_configuration/2.4_Python_Usage) 以获得更好体验。

## 第三方 AI 框架支持

在 **[5.2 AI 框架支持](5.2_AI_Framework_Support/index.md)** 章节中，我们整理了常见的第三方 AI 框架在 **SpacemiT RISC-V 平台** 上的使用方法，例如：

- **OCR**: PaddleOCR
- **视觉检测**: Ultralytics YOLO

通过这些实践，你可以快速移植和运行已有的主流 AI 模型，充分利用 **RISC-V 平台的算力与生态**。

但是请注意，这些框架模型未适配平台加速，使用纯 CPU 计算会带来更高的推理耗时，在生产环境中，你需要使用我们适配好的 `spacemit-ort Python/C++` 软件包来获得硬件加速的能力。

注意：不要在  **SpacemiT RISC-V** 边缘计算平台上执行模型训练流程。


## Demo Zoo 与硬件加速

除了上述示例与第三方框架，我们还维护了一个 [**Demo Zoo**](https://gitee.com/bianbu/spacemit-demo)，其中包含了基于 **SpacemiT RISC-V 平台** 的完整 AI 演示集合。

在 Demo Zoo 中，我们特别强调了对 **ONNX Runtime (ORT)** 的支持：
- ORT 已经在我们的平台上完成适配，对应的 `python` 软件包为 `spacemit-ort`
- 借助硬件加速单元（AI NPU），可以实现 **更低延迟、更高吞吐** 的推理
- 提供了统一的接口，方便用户在 Demo Zoo 中快速加载和运行不同模型

这意味着你不仅可以运行标准示例，还能体验 **经过硬件加速优化的 AI 性能**。


## 建议的学习顺序

为了更好地掌握本章节内容，推荐以下学习路径：

1. **快速开始** —— 先运行我们的语音与大模型示例，直观了解平台能力。
2. **第三方框架支持** —— 学习如何在 RISC-V 上移植并运行常见框架模型，并快速验证一些算法的可行性。
3. **Demo Zoo** —— 结合 ORT 硬件加速，体验我们优化过的 AI 推理效果，并考虑将 pytorch 等框架下的模型迁移到 onnxruntime 并适配我们平台的硬件加速以获得性能上的提升。

通过这一顺序，你将逐步理解从示例到生态，再到硬件加速的完整链路。

