sidebar_position: 1

# 5.2.1 Ultralytics Usage Guide

## Overview

Ultralytics is a company focused on **computer vision and deep learning**, best known as a key developer and maintainer of the famous **YOLO (You Only Look Once)** series of object detection models. The name refers to both the team and their open-source Python library. 

- **Core Product**
  **Ultralytics YOLO**: A top open-source solution for object detection and image segmentation, supporting **YOLOv3/v5/v8/v9/v11**.

- **Main Features**
  - **Object Detection**: Identifies and locates objects in images or videos.
  - **Segmentation**: Segments objects at the pixel level.
  - **Pose Estimation**: Detects human keypoints.
  - **Classification**: Performs image classification tasks.

- **Ecosystem Features**
  - Pure **Python** implementation based on **PyTorch**.
  - Easy installation via `pip install ultralytics`.
  - Includes command-line tools and Python API out of the box.
  - Offers training, validation, inference, and export tools.
  - Supports deployment multiple formats like ONNX, TensorRT, CoreML, and OpenVINO (use **ONNX** for SpacemiT RISC-V).

More about Ultralytics, please visit **[Ultralytics Official Page](https://www.ultralytics.com/)**

### Application Areas

- Video surveillance and security
- Autonomous driving and traffic analysis
- Industrial inspection and robot vision
- Medical image analysis
- Smart retail

## Framework Adaptation Notes

Ultralytics uses PyTorch as its backend framework. 
**Note:** PyTorch currently does not leverage hardware acceleration on SpacemiT RISC-V platforms.

- You can use Ultralytics on our platform for **quick algorithm validation and prototyping**.
- For **deployment with hardware acceleration**, use the `spacemit-ort` framework.
- Refer to the [Demo Zoo](https://gitee.com/bianbu/spacemit-demo) and [Model Quantization Guide](/en/07_Advanced_development/7.1_Model_Quantization.md) for details on optimized deployment.

## Environment Setup

### Install Dependencies

```bash
sudo apt install python3-pip python3-venv libxrender1 libgl1 libglib2.0-0t64
```

### Platform Requirements

**SpacemiT RISC-V Board**: Must have the **Bianbu ROS** system image flashed.

## Installing Ultralytics

### Set Up Sources

```bash
pip config set global.index-url https://mirrors.aliyun.com/pypi/simple/
pip config set global.extra-index-url https://git.spacemit.com/api/v4/projects/33/packages/pypi/simple
```

### Create and Activate a Virtual Environment

```bash
python3 -m venv test1
source test1/bin/activate
pip install pip -U
```

### Install Ultralytics

```bash
pip install --prefer-binary ultralytics 
```

Expected output after installation:

![](./images/ultra_install.png)

## Test the Installation

Sample Code Source: https://docs.ultralytics.com/zh/modes/predict/#plotting-results

**Note:** This example involves visualization. Please connect an HDMI screen, keyboard, and mouse to the board to run the commands locally.

- Create a file named `demo1.py` with the following content:

  ```python
  from PIL import Image

  from ultralytics import YOLO

  # Load a pretrained YOLO11n model
  model = YOLO("yolo11n.pt")

  # Run inference on 'bus.jpg'
  results = model(["https://ultralytics.com/images/bus.jpg", "https://ultralytics.com/images/zidane.jpg"])  # results list

  # Visualize the results
  for i, r in enumerate(results):
    # Plot results image
    im_bgr = r.plot()  # BGR-order numpy array
    im_rgb = Image.fromarray(im_bgr[..., ::-1])  # RGB-order PIL image

    # Show results to screen (in supported environments)
    r.show()

    # Save results to disk
    r.save(filename=f"results{i}.jpg")
  ```

- Run:

  ```bash
  source test1/bin/activate
  python demo1.py
  ```

- Expected Output:

  ![](./images/ultra_infer_res.png)