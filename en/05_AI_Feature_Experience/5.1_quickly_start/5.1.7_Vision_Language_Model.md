sidebar_position: 7

# 5.1.7 Vision Language Model (VLM)

## Overview

This section explains how to use **Vision-Language Models (VLMs)** to understand images and generate text.

Using **SmolVLM** as an example, the model can take an image as input and produce natural language output. It also supports running locally without an internet connection.

## Clone Repository

Get the project files.

```bash
git clone https://gitee.com/bianbu/spacemit-demo.git
cd spacemit-demo/examples/NLP
```

## Install Dependencies

### Install Models and the Ollama Toolkit

Install the Spacemit Ollama toolkit:

```bash
sudo apt install spacemit-ollama-toolkit
```

Verify the installation:

```bash
ollama list
```

If the output displays the columns `NAME  ID  SIZE  MODIFIED`, the installation is successful.

Check the installed version (version **0.0.8 or later** is required):

```bash
sudo apt show spacemit-ollama-toolkit
```

Ensure the version is **0.0.8 or above** to support the SmolVLM vision-language model.

Download and prepare the SmolVLM model

```bash
wget https://archive.spacemit.com/spacemit-ai/gguf/mmproj-SmolVLM-256M-Instruct-Q8_0.gguf
wget https://archive.spacemit.com/spacemit-ai/gguf/SmolVLM-256M-Instruct-f16.gguf
wget https://archive.spacemit.com/spacemit-ai/modelfile/smolvlm.modelfile

# Create the model using Ollama
ollama create smolvlm:256m -f smolvlm.modelfile
```

**Note:** If you want to switch to a different model, update the corresponding configuration in the `modelfile`.

### Install Python Environment Dependencies

```bash
sudo apt install python3-venv python3-pip

python3 -m venv .venv
source .venv/bin/activate

pip install -r requirements.txt
```

## Run the Inference Task

Run the following command to perform vision-language inference on a local image:

```bash
python 08_vision_demo.py --image=bus.jpg --stream=True --prompt="describe this image"
```

The model will generate a natural language description based on the input image (`bus.jpg`) and the provided text prompt (`describe this image`).

