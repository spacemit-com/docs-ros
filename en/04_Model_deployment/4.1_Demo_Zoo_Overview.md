sidebar_position: 1

# 4.1 Demo Zoo Overview

## Overview

The **Bianbu AI Demo Zoo** is a collection of sample projects developed by **SpacemiT**. It provides reference implementations for deploying various deep learning models on **K1 series chips**. THis demonstrates an **end-to-end inference workflow**.

The project is organized into two main branches:

- **Computer Vision (CV):** Covers tasks like image classification, object detection, and face recognition.
- **Natural Language Processing (NLP):** Supports typical NLP tasks (see repository for details).

Both branches support **C++** and **Python**, making them suitable for **real-world deployment scenarios**.

- Project repository: [AI Demo Zoo](https://gitee.com/bianbu/spacemit-demo.git)
- Supported models: For details, see the full [Model List](https://gitee.com/bianbu/spacemit-demo/blob/main/README.md#cv%E6%A8%A1%E5%9E%8B%E6%80%A7%E8%83%BD). 
Currently, it covers common models such as

  - **Classification:** ResNet, MobileNet
  - **Detection:** YOLOv5, YOLOX
  - **Face Recognition:** ArcFace

## Demos

Most models provide **inference examples** in both Python and C++. After downloading the required **model weights** and **test data** (see `README.md` for step-by-step instructions).

### Python Demo

Taking **ResNet** image classification as an example:

```shell
cd python
python test_resnet.py  # Default to using the ResNet50 model.
```

After the model finishes running, it will output the predicted class labels. 

### C++ Demo 

```bash
cd cpp
mkdir build
cd build
cmake ..
make -j8
./resnet_demo --model /path/to/resnet50.onnx --image /path/to/image.jpg
```

After running, the prediction results will also be output in the terminal. You can combine this with **OpenCV** to render the classification labels.

## Supported Model List

| Model Category |     Specific Model    |              Input Size              |
| :------------: | :-------------------: | :----------------------------------: |
|  EfficientNet  |    EfficientNet_b1    |           [1, 3, 224, 224]           |
|    Inception   |      Inception_v1     |           [1, 3, 224, 224]           |
|                |      Inception_v3     |           [1, 3, 229, 229]           |
|    MobileNet   |      MobileNetv2      |           [1, 3, 224, 224]           |
|     ResNet     |        ResNet50       |           [1, 3, 224, 224]           |
|     YOLOv5     |        YOLOv5n        |           [1, 3, 640, 640]           |
|     YOLOv6     |        YOLOv6n        |           [1, 3, 320, 320]           |
|     YOLOv8     |        YOLOv8n        |           [1, 3, 320, 320]           |
|                |        YOLOv8n        |           [1, 3, 192, 320]           |
|     YOLOv11    |        YOLOv11n       |           [1, 3, 320, 320]           |
|    NanoTrack   |       NanoTrack       |           [1, 3, 255, 255]           |
|     ArcFace    | arcface_mobilefacenet |           [1, 3, 320, 320]           |
|   YOLOv5-face  |      YOLOv5n-face     |           [1, 3, 320, 320]           |
|      CLIP      |          CLIP         |             Dynamic input            |
|       SAM      |          SAM          | [1, 3, 1024, 1024], [1, 1, 256, 256] |
|       FCN      |          FCN          |           [1, 3, 512, 512]           |
|      Swin      |       Swin-Tiny       |           [1, 3, 224, 224]           |
|      UNet      |          UNet         |           [1, 3, 512, 512]           |
|   YOLO-World   |     YOLOv8s-World     |           [1, 3, 320, 320]           |
|   YOLOv8-OBB   |      YOLOv8n-OBB      |           [1, 3, 320, 320]           |
|   YOLOv8-Seg   |      YOLOv8n-Seg      |           [1, 3, 320, 320]           |
|   YOLOv8-Pose  |      YOLOv8n-Pose     |           [1, 3, 320, 320]           |
|   MobileSAM1   |       MobileSAM1      | [1, 3, 1024, 1024], [1, 1, 256, 256] |
|      YOLOE     |         YOLOE         |           [1, 3, 320, 320]           |

